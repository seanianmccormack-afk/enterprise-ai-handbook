The Enterprise AI Handbook
What actually works, what doesn't, and how to tell the difference.
Most enterprise AI pilots fail. The corporate response has been to rename them. This handbook exists because practitioners and decision-makers deserve a framework grounded in research, not vendor pitches.
It is free, it will stay free, and it gets better when practitioners contribute.
What's In It
Twelve standalone sections covering the full arc from reality check to long-term institutional capacity:
1. Who this is for
2. The reality check — what the data actually says
3. Where to aim — start with extractive gains that make work better, earn trust, then find compounding opportunities
4. The model is not the product — architecture matters more than the model
5. The data bottleneck — and why you start with a sandbox
6. Shadow AI — your cheapest discovery mechanism
7. Verification math — the concept that kills bad proposals
8. Know what you're buying — consulting conflicts and translation layer risk
9. Go/no-go decision framework
10. Phased deployment — readiness → pilot → production → scale
11. Measuring real value — ROI and Return on Employee
12. The long view — building institutional capacity across successive AI waves
Who It's For
People deploying AI inside companies. People deciding whether to fund, approve, or kill AI proposals. Anyone who has heard the sales pitch and needs a framework for evaluating whether it matches reality.
How to Use It
Read the handbook: enterprise_ai_handbook.md
Read it straight through or jump to the section that matches where you are. Each section stands alone. Use it internally, share it with your leadership, adapt it for your organization.
Contributing
War stories, corrections, better data, sharper frameworks — all welcome. Open a pull request or start a discussion. The goal is a living document written by practitioners, not vendors.
License
CC v 1.0. Use it, adapt it, distribute it.
________________


A Shelter Dog Communications project. No BS. No hate. Just curiosity.
